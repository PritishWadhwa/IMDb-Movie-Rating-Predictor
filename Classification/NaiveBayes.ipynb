{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXYP3pIc485l",
        "outputId": "9e3efe09-12af-4c79-fda5-1c167cddb4a2"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gVipYT95I3Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj6z6HHb5Mrr"
      },
      "source": [
        "testData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_test.csv')\n",
        "trainData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_train.csv')\n",
        "validData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_val.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aau1W10F5cvZ",
        "outputId": "81fdee55-9f81-4830-f050-5ccebb610076"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(testData)\n",
        "scaler.fit(trainData)\n",
        "scaler.fit(validData)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq_u4YQv4kZ0"
      },
      "source": [
        "# Six buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XHg-UJl4kZ9"
      },
      "source": [
        "train_data_target_6k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/train_6_buckets.csv')\n",
        "test_data_target_6k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/test_6_buckets.csv')\n",
        "val_data_target_6k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/valid_6_buckets.csv')\n",
        "testData['data_IMDBscore']=test_data_target_6k['data_IMDBscore']\n",
        "trainData['data_IMDBscore']=train_data_target_6k['data_IMDBscore']\n",
        "validData ['data_IMDBscore']=val_data_target_6k['data_IMDBscore']\n",
        "train_X = trainData.drop(columns=['data_IMDBscore'])\n",
        "train_Y = trainData['data_IMDBscore']\n",
        "test_X = testData.drop(columns=['data_IMDBscore'])\n",
        "test_Y = testData['data_IMDBscore']\n",
        "val_X=validData.drop(columns=['data_IMDBscore'])\n",
        "val_Y=validData['data_IMDBscore']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soWcgrVl4kZ-"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omsub1ZrNsDe"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlll8KqpNsTw"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amf4cgINNsTw",
        "outputId": "73fad3ee-40f6-42cd-a391-eeaf0e25b4d3"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.5095169857702235\n",
            "train_precision_score 0.7058121553144622\n",
            "train_recall_score 0.4814717649373647\n",
            "train_accuracy_score 0.4814717649373647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw5m-YD8NsTx",
        "outputId": "3de4c26a-99e9-4c39-e108-0bbd78849636"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.3939607167856544\n",
            "val_precision_score 0.5499388243340402\n",
            "val_recall_score 0.367003367003367\n",
            "val_accuracy_score 0.367003367003367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIoSTYUtNsTx",
        "outputId": "9182b1aa-0014-41a4-cc5e-8b5facce28a6"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.39614748918410636\n",
            "test_precision_score 0.5794965696618789\n",
            "test_recall_score 0.37178702570379435\n",
            "test_accuracy_score 0.37178702570379435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU9-3jm44kZ-"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Create a Multinomial Classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBNuwOntNpaq"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auu4SFItNpmu"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjhQpzpfNpmv",
        "outputId": "ae025dad-0ad9-4080-d511-316d749d1e68"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.52526718634361\n",
            "train_precision_score 0.6025189109608157\n",
            "train_recall_score 0.4922935659473995\n",
            "train_accuracy_score 0.4922935659473995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mypnBDTONpmv",
        "outputId": "dbc3a8c4-22a5-4d04-d812-e8b535c5e13f"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.49231942845556\n",
            "val_precision_score 0.5596035411542802\n",
            "val_recall_score 0.46219773492500765\n",
            "val_accuracy_score 0.46219773492500765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh79E1W5Npmw",
        "outputId": "48608691-4968-4d4b-8088-c07585bb792c"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.49169053598481643\n",
            "test_precision_score 0.5593442965771962\n",
            "test_recall_score 0.46328029375764995\n",
            "test_accuracy_score 0.46328029375764995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-FGOfhe4kZ_"
      },
      "source": [
        "#Import Bernoulli Naive Bayes model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "#Create a Bernoulli Classifier\n",
        "model = BernoulliNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8v9a2SqNmwF"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7hQ1R7rNnD0"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxUV6Mc5NnD1",
        "outputId": "2ef03104-2ca9-4b2f-c493-b872e4d784af"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.6669035388980268\n",
            "train_precision_score 0.6769145787602228\n",
            "train_recall_score 0.6630812618875844\n",
            "train_accuracy_score 0.6630812618875844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb8vd9T9NnD1",
        "outputId": "ea422059-2116-41fe-fc4d-4ee62e8c2326"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.6015278658908343\n",
            "val_precision_score 0.6061249283301678\n",
            "val_recall_score 0.5990205081114172\n",
            "val_accuracy_score 0.5990205081114172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voW91x7QNnD2",
        "outputId": "a085720d-844d-41fd-f595-df1e92d2421f"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.5899234937295681\n",
            "test_precision_score 0.5977405356675818\n",
            "test_recall_score 0.5865973072215422\n",
            "test_accuracy_score 0.5865973072215422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9-2S1Wq9Mb5",
        "outputId": "4fdc7947-77df-4b59-fb49-74e67be9ffea"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M67C6Ixe9eCa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlQtQs7P9oiQ"
      },
      "source": [
        "testData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_test.csv')\n",
        "trainData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_train.csv')\n",
        "validData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_val.csv')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tMEfhTv3gFg",
        "outputId": "959c9c58-62fb-4cc0-f371-77aebc38faca"
      },
      "source": [
        "#Min Max Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(testData)\n",
        "scaler.fit(trainData)\n",
        "scaler.fit(validData )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3pwl38XypcU"
      },
      "source": [
        "# Eleven Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1bsG9xl9qpN"
      },
      "source": [
        "train_data_target_11k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/train_11_buckets.csv')\n",
        "test_data_target_11k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/test_11_buckets.csv')\n",
        "val_data_target_11k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/valid_11_buckets.csv')\n",
        "testData['data_IMDBscore']=test_data_target_11k['data_IMDBscore']\n",
        "trainData['data_IMDBscore']=train_data_target_11k['data_IMDBscore']\n",
        "validData ['data_IMDBscore']=val_data_target_11k['data_IMDBscore']\n",
        "train_X = trainData.drop(columns=['data_IMDBscore'])\n",
        "train_Y = trainData['data_IMDBscore']\n",
        "test_X = testData.drop(columns=['data_IMDBscore'])\n",
        "test_Y = testData['data_IMDBscore']\n",
        "val_X=validData.drop(columns=['data_IMDBscore'])\n",
        "val_Y=validData['data_IMDBscore']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9AGN0cd-Hb5"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5i4sSdJNiRP"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpUrMUyNihf"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8RJ6FJNihg",
        "outputId": "0258906c-03cf-4df0-bdee-da7debf1859d"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.3416329031247324\n",
            "train_precision_score 0.5987241624186435\n",
            "train_recall_score 0.36072670033449206\n",
            "train_accuracy_score 0.36072670033449206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lua2WMQUNihg",
        "outputId": "828a12d8-8807-4388-e0d1-10682e18dec3"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.21261272031931835\n",
            "val_precision_score 0.38584419049541907\n",
            "val_recall_score 0.2157943067033976\n",
            "val_accuracy_score 0.2157943067033976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5SSQX-fNihh",
        "outputId": "1cb55b09-d2f3-4365-a730-8daee38bd482"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.20331963351274432\n",
            "test_precision_score 0.3809732121973175\n",
            "test_recall_score 0.2086903304773562\n",
            "test_accuracy_score 0.2086903304773562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMwHsqV3-mz"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Create a Multinomial Classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gvqTNUNfSI"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka25WsGMNfgP"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1zD7B8NfgP",
        "outputId": "1fd834f0-d265-45a1-ff81-4a8e3f57715a"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.39030871364573216\n",
            "train_precision_score 0.4449025490252472\n",
            "train_recall_score 0.36498983406571783\n",
            "train_accuracy_score 0.36498983406571783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN97Dd58NfgQ",
        "outputId": "3d2d4173-06b4-439c-f87d-8bb7967c5fb8"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.31994857546497973\n",
            "val_precision_score 0.35812519312556174\n",
            "val_recall_score 0.30058157330884605\n",
            "val_accuracy_score 0.30058157330884605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dh5b3lPNfgQ",
        "outputId": "ea7f65aa-d8df-42b9-be4a-c2df394f3b79"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.3166920435500863\n",
            "test_precision_score 0.36040704360812953\n",
            "test_recall_score 0.29834761321909425\n",
            "test_accuracy_score 0.29834761321909425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMA5wEnP4POL"
      },
      "source": [
        "#Import Bernoulli Naive Bayes model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "#Create a Bernoulli Classifier\n",
        "model = BernoulliNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6v86VJNc2w"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dG36w4oNdHr"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmLATyU8NdHs",
        "outputId": "7b452375-08fe-4cd3-f2a2-a899e7d0d7d3"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.5493023587383756\n",
            "train_precision_score 0.5515016587373647\n",
            "train_recall_score 0.5523709582212895\n",
            "train_accuracy_score 0.5523709582212895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JF5R_yBNdHt",
        "outputId": "52022fde-e7d3-45ce-a38a-1d5abdeed728"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.39757973912038397\n",
            "val_precision_score 0.3950763417477658\n",
            "val_recall_score 0.4061830425466789\n",
            "val_accuracy_score 0.4061830425466789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TScdPoSLNdHt",
        "outputId": "c831a7c0-7d4d-4c70-a17a-1b94baabd318"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.40427661271381266\n",
            "test_precision_score 0.40257973765831695\n",
            "test_recall_score 0.4121787025703794\n",
            "test_accuracy_score 0.4121787025703794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j9Z9z3j4wqU"
      },
      "source": [
        "# TwentyOne Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W7XvuQ_4wqV"
      },
      "source": [
        "train_data_target_21k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/train_21_buckets.csv')\n",
        "test_data_target_21k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/test_21_buckets.csv')\n",
        "val_data_target_21k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/valid_21_buckets.csv')\n",
        "testData['data_IMDBscore']=test_data_target_21k['data_IMDBscore']\n",
        "trainData['data_IMDBscore']=train_data_target_21k['data_IMDBscore']\n",
        "validData ['data_IMDBscore']=val_data_target_21k['data_IMDBscore']\n",
        "train_X = trainData.drop(columns=['data_IMDBscore'])\n",
        "train_Y = trainData['data_IMDBscore']*2\n",
        "test_X = testData.drop(columns=['data_IMDBscore'])\n",
        "test_Y = testData['data_IMDBscore']*2\n",
        "val_X=validData.drop(columns=['data_IMDBscore'])\n",
        "val_Y=validData['data_IMDBscore']*2"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTdbMn44wqW"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5DVrMfQNZkb"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnNyTrv4NZ0L"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk9Xhpz9NZ0M",
        "outputId": "899c978a-aa3e-438e-ea2b-2491db6e0249"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.29310840411605066\n",
            "train_precision_score 0.5306531562000959\n",
            "train_recall_score 0.3268183905030498\n",
            "train_accuracy_score 0.3268183905030498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrsNqHZDNZ0M",
        "outputId": "0a251571-6bb2-4570-b69c-ec05420e6793"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.1131555967237213\n",
            "val_precision_score 0.20838227224731107\n",
            "val_recall_score 0.12396694214876033\n",
            "val_accuracy_score 0.12396694214876033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcqY6l9NZ0N",
        "outputId": "2abf9acc-f766-499d-b79b-72d344a0798b"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.10715209726309584\n",
            "test_precision_score 0.20063761719143178\n",
            "test_recall_score 0.1153610771113831\n",
            "test_accuracy_score 0.1153610771113831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsukWaYV4wqW"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Create a Multinomial Classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n",
        "#Import scikit-learn metrics module for accuracy calculation\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKYFttdXNVJr"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKhkGiVNNVoM"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-XGtTOVNVoM",
        "outputId": "a4288426-b3f0-4946-fc67-82ced1068883"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.29814505859393864\n",
            "train_precision_score 0.3373894267504772\n",
            "train_recall_score 0.2864825867383748\n",
            "train_accuracy_score 0.2864825867383748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WedJY6sPNVoN",
        "outputId": "81b1710d-7665-4dcc-93c8-62be34f43f10"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.18037674638461415\n",
            "val_precision_score 0.19976046902140723\n",
            "val_recall_score 0.17324762779308234\n",
            "val_accuracy_score 0.17324762779308234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZGPx0wyNVoO",
        "outputId": "3e7dce54-abcf-4b5e-a41d-58e75fb96f05"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.17881194791413407\n",
            "test_precision_score 0.2003973030571113\n",
            "test_recall_score 0.17288861689106488\n",
            "test_accuracy_score 0.17288861689106488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPfiDkLu4wqW",
        "outputId": "8623ed9f-b4c7-4bd4-e934-cd7cc4d55f2a"
      },
      "source": [
        "#Import Bernoulli Naive Bayes model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "#Create a Bernoulli Classifier\n",
        "model = BernoulliNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test set\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8j_UvltMp9o"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQpsroIGMo0B",
        "outputId": "00601c4d-a835-48a2-c97b-c01ce22044ee"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.46511676460464124\n",
            "train_precision_score 0.4678915022476538\n",
            "train_recall_score 0.4704532039089657\n",
            "train_accuracy_score 0.4704532039089657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_shuNanMast",
        "outputId": "4fc34171-648a-4081-e665-2cd289da3bc9"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.21212156236178384\n",
            "val_precision_score 0.20971588444682998\n",
            "val_recall_score 0.21977349250076522\n",
            "val_accuracy_score 0.21977349250076522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVRaXnK1McA_",
        "outputId": "8f33c5fe-2453-4d54-9150-9fc19b5e7be2"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.22155749790124293\n",
            "test_precision_score 0.21737261595457202\n",
            "test_recall_score 0.2294981640146879\n",
            "test_accuracy_score 0.2294981640146879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}