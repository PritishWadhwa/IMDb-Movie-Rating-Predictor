{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXYP3pIc485l",
        "outputId": "f689b27b-a501-4d0c-fed3-0816f68ee581"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gVipYT95I3Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj6z6HHb5Mrr"
      },
      "source": [
        "testData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_test.csv')\n",
        "trainData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_train.csv')\n",
        "validData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_val.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aau1W10F5cvZ",
        "outputId": "bba9dedb-a9a4-429e-8178-8965996354a3"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(trainData)\n",
        "scaler.transform(trainData)\n",
        "scaler.transform(trainData)\n",
        "scaler.transform(validData)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14117647, 0.16666667, 0.12142039, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.03529412, 0.10833333, 0.14203895, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.00833333, 0.02634593, ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [0.        , 0.00833333, 0.11912944, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.06666667, 0.13287514, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.00833333, 0.09965636, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq_u4YQv4kZ0"
      },
      "source": [
        "# Six buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XHg-UJl4kZ9"
      },
      "source": [
        "train_data_target_6k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/train_6_buckets.csv')\n",
        "test_data_target_6k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/test_6_buckets.csv')\n",
        "val_data_target_6k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/valid_6_buckets.csv')\n",
        "testData['data_IMDBscore']=test_data_target_6k['data_IMDBscore']\n",
        "trainData['data_IMDBscore']=train_data_target_6k['data_IMDBscore']\n",
        "validData ['data_IMDBscore']=val_data_target_6k['data_IMDBscore']\n",
        "train_X = trainData.drop(columns=['data_IMDBscore'])\n",
        "train_Y = trainData['data_IMDBscore']\n",
        "test_X = testData.drop(columns=['data_IMDBscore'])\n",
        "test_Y = testData['data_IMDBscore']\n",
        "val_X=validData.drop(columns=['data_IMDBscore'])\n",
        "val_Y=validData['data_IMDBscore']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soWcgrVl4kZ-"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omsub1ZrNsDe"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/GNB_6_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlll8KqpNsTw"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amf4cgINNsTw",
        "outputId": "e28be45f-ff2c-4883-b786-fb49aacb4b4c"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.5095169857702235\n",
            "train_precision_score 0.7058121553144622\n",
            "train_recall_score 0.4814717649373647\n",
            "train_accuracy_score 0.4814717649373647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw5m-YD8NsTx",
        "outputId": "476b7a3d-b716-4d0d-9757-0436b0143a18"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.3939607167856544\n",
            "val_precision_score 0.5499388243340402\n",
            "val_recall_score 0.367003367003367\n",
            "val_accuracy_score 0.367003367003367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIoSTYUtNsTx",
        "outputId": "f4180f1e-e125-4f26-96ab-b9efa02332bb"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.39614748918410636\n",
            "test_precision_score 0.5794965696618789\n",
            "test_recall_score 0.37178702570379435\n",
            "test_accuracy_score 0.37178702570379435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU9-3jm44kZ-"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Create a Multinomial Classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT9dyqzXJaJK"
      },
      "source": [
        "Saving Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBNuwOntNpaq"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/MNB_6_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auu4SFItNpmu"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjhQpzpfNpmv",
        "outputId": "f71d9fa2-7b1f-4f5d-f084-486d32a82c10"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.52526718634361\n",
            "train_precision_score 0.6025189109608157\n",
            "train_recall_score 0.4922935659473995\n",
            "train_accuracy_score 0.4922935659473995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mypnBDTONpmv",
        "outputId": "ef9287d2-8726-4d67-fb70-822d4bcb3bef"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.49231942845556\n",
            "val_precision_score 0.5596035411542802\n",
            "val_recall_score 0.46219773492500765\n",
            "val_accuracy_score 0.46219773492500765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh79E1W5Npmw",
        "outputId": "0d1bb85a-218f-40c6-c191-f5168edaae05"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.49169053598481643\n",
            "test_precision_score 0.5593442965771962\n",
            "test_recall_score 0.46328029375764995\n",
            "test_accuracy_score 0.46328029375764995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-FGOfhe4kZ_"
      },
      "source": [
        "#Import Bernoulli Naive Bayes model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "#Create a Bernoulli Classifier\n",
        "model = BernoulliNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8v9a2SqNmwF"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/BNB_6_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7hQ1R7rNnD0"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxUV6Mc5NnD1",
        "outputId": "bd39ea92-724f-4168-9191-5fa9b070d844"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.6669035388980268\n",
            "train_precision_score 0.6769145787602228\n",
            "train_recall_score 0.6630812618875844\n",
            "train_accuracy_score 0.6630812618875844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb8vd9T9NnD1",
        "outputId": "b2c57413-70ae-4fd4-b2a8-c554b41db5e1"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.6015278658908343\n",
            "val_precision_score 0.6061249283301678\n",
            "val_recall_score 0.5990205081114172\n",
            "val_accuracy_score 0.5990205081114172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voW91x7QNnD2",
        "outputId": "4cd53772-1f90-4cf8-af12-90cc2e4aef06"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.5899234937295681\n",
            "test_precision_score 0.5977405356675818\n",
            "test_recall_score 0.5865973072215422\n",
            "test_accuracy_score 0.5865973072215422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9-2S1Wq9Mb5",
        "outputId": "da962602-3df8-4623-e4b6-4381c1d0c52b"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M67C6Ixe9eCa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlQtQs7P9oiQ"
      },
      "source": [
        "testData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_test.csv')\n",
        "trainData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_train.csv')\n",
        "validData = pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/pre_standardization_val.csv')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tMEfhTv3gFg",
        "outputId": "4388a82a-475a-43da-e0da-de882affc3aa"
      },
      "source": [
        "#Min Max Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(testData)\n",
        "scaler.fit(trainData)\n",
        "scaler.fit(validData )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3pwl38XypcU"
      },
      "source": [
        "# Eleven Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1bsG9xl9qpN"
      },
      "source": [
        "train_data_target_11k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/train_11_buckets.csv')\n",
        "test_data_target_11k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/test_11_buckets.csv')\n",
        "val_data_target_11k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/valid_11_buckets.csv')\n",
        "testData['data_IMDBscore']=test_data_target_11k['data_IMDBscore']\n",
        "trainData['data_IMDBscore']=train_data_target_11k['data_IMDBscore']\n",
        "validData ['data_IMDBscore']=val_data_target_11k['data_IMDBscore']\n",
        "train_X = trainData.drop(columns=['data_IMDBscore'])\n",
        "train_Y = trainData['data_IMDBscore']\n",
        "test_X = testData.drop(columns=['data_IMDBscore'])\n",
        "test_Y = testData['data_IMDBscore']\n",
        "val_X=validData.drop(columns=['data_IMDBscore'])\n",
        "val_Y=validData['data_IMDBscore']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9AGN0cd-Hb5"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5i4sSdJNiRP"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/GNB_11_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpUrMUyNihf"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8RJ6FJNihg",
        "outputId": "f662305c-9338-4216-86b7-a124d0160fad"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.3416329031247324\n",
            "train_precision_score 0.5987241624186435\n",
            "train_recall_score 0.36072670033449206\n",
            "train_accuracy_score 0.36072670033449206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lua2WMQUNihg",
        "outputId": "5439501c-7109-4bc3-b319-388673a6378a"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.21261272031931835\n",
            "val_precision_score 0.38584419049541907\n",
            "val_recall_score 0.2157943067033976\n",
            "val_accuracy_score 0.2157943067033976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5SSQX-fNihh",
        "outputId": "a85ef594-fead-4da8-a6c7-ba82d2204286"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.20331963351274432\n",
            "test_precision_score 0.3809732121973175\n",
            "test_recall_score 0.2086903304773562\n",
            "test_accuracy_score 0.2086903304773562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMwHsqV3-mz"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Create a Multinomial Classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gvqTNUNfSI"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/MNB_11_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka25WsGMNfgP"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1zD7B8NfgP",
        "outputId": "220add0d-e514-4fb8-b13d-04d87a9b2a27"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.39030871364573216\n",
            "train_precision_score 0.4449025490252472\n",
            "train_recall_score 0.36498983406571783\n",
            "train_accuracy_score 0.36498983406571783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN97Dd58NfgQ",
        "outputId": "98590fb6-7c3e-4fc9-90d9-3ca0c6cc7582"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.31994857546497973\n",
            "val_precision_score 0.35812519312556174\n",
            "val_recall_score 0.30058157330884605\n",
            "val_accuracy_score 0.30058157330884605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dh5b3lPNfgQ",
        "outputId": "c3829ca6-5b6e-45fc-df55-dec7e2e40179"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.3166920435500863\n",
            "test_precision_score 0.36040704360812953\n",
            "test_recall_score 0.29834761321909425\n",
            "test_accuracy_score 0.29834761321909425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMA5wEnP4POL"
      },
      "source": [
        "#Import Bernoulli Naive Bayes model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "#Create a Bernoulli Classifier\n",
        "model = BernoulliNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6v86VJNc2w"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/BNB_11_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dG36w4oNdHr"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmLATyU8NdHs",
        "outputId": "762ea128-699d-4be5-bd6d-d5e5660b21be"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.5493023587383756\n",
            "train_precision_score 0.5515016587373647\n",
            "train_recall_score 0.5523709582212895\n",
            "train_accuracy_score 0.5523709582212895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JF5R_yBNdHt",
        "outputId": "134de888-e62d-4317-84ce-c72ddd07c013"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.39757973912038397\n",
            "val_precision_score 0.3950763417477658\n",
            "val_recall_score 0.4061830425466789\n",
            "val_accuracy_score 0.4061830425466789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TScdPoSLNdHt",
        "outputId": "046ceb6a-6ddd-42f3-81b7-e49955c297af"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.40427661271381266\n",
            "test_precision_score 0.40257973765831695\n",
            "test_recall_score 0.4121787025703794\n",
            "test_accuracy_score 0.4121787025703794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j9Z9z3j4wqU"
      },
      "source": [
        "# TwentyOne Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W7XvuQ_4wqV"
      },
      "source": [
        "train_data_target_21k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/train_21_buckets.csv')\n",
        "test_data_target_21k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/test_21_buckets.csv')\n",
        "val_data_target_21k=pd.read_csv('/content/gdrive/MyDrive/ML_Project/Dataset/valid_21_buckets.csv')\n",
        "testData['data_IMDBscore']=test_data_target_21k['data_IMDBscore']\n",
        "trainData['data_IMDBscore']=train_data_target_21k['data_IMDBscore']\n",
        "validData ['data_IMDBscore']=val_data_target_21k['data_IMDBscore']\n",
        "train_X = trainData.drop(columns=['data_IMDBscore'])\n",
        "train_Y = trainData['data_IMDBscore']*2\n",
        "test_X = testData.drop(columns=['data_IMDBscore'])\n",
        "test_Y = testData['data_IMDBscore']*2\n",
        "val_X=validData.drop(columns=['data_IMDBscore'])\n",
        "val_Y=validData['data_IMDBscore']*2"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTdbMn44wqW"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5DVrMfQNZkb"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/GNB_21_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnNyTrv4NZ0L"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk9Xhpz9NZ0M",
        "outputId": "fe56768f-9bb2-4480-d80b-566dea431afb"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.29310840411605066\n",
            "train_precision_score 0.5306531562000959\n",
            "train_recall_score 0.3268183905030498\n",
            "train_accuracy_score 0.3268183905030498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrsNqHZDNZ0M",
        "outputId": "721101d2-d719-427e-ca8e-a4c375e1c36b"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.1131555967237213\n",
            "val_precision_score 0.20838227224731107\n",
            "val_recall_score 0.12396694214876033\n",
            "val_accuracy_score 0.12396694214876033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcqY6l9NZ0N",
        "outputId": "adf83c58-2882-45a3-bb78-7266532db244"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.10715209726309584\n",
            "test_precision_score 0.20063761719143178\n",
            "test_recall_score 0.1153610771113831\n",
            "test_accuracy_score 0.1153610771113831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsukWaYV4wqW"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Create a Multinomial Classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(test_X)\n",
        "#Import scikit-learn metrics module for accuracy calculation\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKYFttdXNVJr"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/MNB_21_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKhkGiVNNVoM"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-XGtTOVNVoM",
        "outputId": "c487f3f8-dbd0-489b-fb5e-a65c7a523e71"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.29814505859393864\n",
            "train_precision_score 0.3373894267504772\n",
            "train_recall_score 0.2864825867383748\n",
            "train_accuracy_score 0.2864825867383748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WedJY6sPNVoN",
        "outputId": "d09819fe-02b6-4029-f52e-5425c9c02d13"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.18037674638461415\n",
            "val_precision_score 0.19976046902140723\n",
            "val_recall_score 0.17324762779308234\n",
            "val_accuracy_score 0.17324762779308234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZGPx0wyNVoO",
        "outputId": "2138c3c2-ed41-4357-fbb9-00e057b5619c"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.17881194791413407\n",
            "test_precision_score 0.2003973030571113\n",
            "test_recall_score 0.17288861689106488\n",
            "test_accuracy_score 0.17288861689106488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPfiDkLu4wqW",
        "outputId": "932f690e-de28-43fa-f138-883c57d0ed89"
      },
      "source": [
        "#Import Bernoulli Naive Bayes model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "#Create a Bernoulli Classifier\n",
        "model = BernoulliNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(train_X,train_Y)\n",
        "#Predict the response for test set\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq59xnJlKgl8"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/SavedModels/BNB_21_'\n",
        "filename=filename+\".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8j_UvltMp9o"
      },
      "source": [
        "trainpred = model.predict(train_X)\n",
        "valpred = model.predict(val_X)\n",
        "testpred = model.predict(test_X)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQpsroIGMo0B",
        "outputId": "8c257fa3-2ca1-4d12-9dee-dde28d3bc8fc"
      },
      "source": [
        "train_f1_score = f1_score(train_Y, trainpred, average='weighted')\n",
        "train_precision_score = precision_score(train_Y, trainpred, average='weighted')\n",
        "train_recall_score = recall_score(train_Y, trainpred, average='weighted')\n",
        "train_accuracy_score = accuracy_score(train_Y, trainpred, normalize=True)\n",
        "print(\"train_f1_score \"+str(train_f1_score) )\n",
        "print(\"train_precision_score \"+str(train_precision_score))\n",
        "print(\"train_recall_score \"+str(train_recall_score))\n",
        "print(\"train_accuracy_score \"+str(train_accuracy_score))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_f1_score 0.46511676460464124\n",
            "train_precision_score 0.4678915022476538\n",
            "train_recall_score 0.4704532039089657\n",
            "train_accuracy_score 0.4704532039089657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_shuNanMast",
        "outputId": "a2b565cf-a056-4e81-b994-970f676b92d4"
      },
      "source": [
        "val_f1_score = f1_score(val_Y, valpred, average='weighted')\n",
        "val_precision_score = precision_score(val_Y, valpred, average='weighted')\n",
        "val_recall_score = recall_score(val_Y, valpred, average='weighted')\n",
        "val_accuracy_score = accuracy_score(val_Y, valpred, normalize=True)\n",
        "print(\"val_f1_score \"+str(val_f1_score) )\n",
        "print(\"val_precision_score \"+str(val_precision_score))\n",
        "print(\"val_recall_score \"+str(val_recall_score))\n",
        "print(\"val_accuracy_score \"+str(val_accuracy_score))\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_f1_score 0.21212156236178384\n",
            "val_precision_score 0.20971588444682998\n",
            "val_recall_score 0.21977349250076522\n",
            "val_accuracy_score 0.21977349250076522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVRaXnK1McA_",
        "outputId": "122082bc-2cb2-4b72-ce46-e7abaf749ade"
      },
      "source": [
        "test_f1_score = f1_score(test_Y, testpred, average='weighted')\n",
        "test_precision_score = precision_score(test_Y, testpred, average='weighted')\n",
        "test_recall_score = recall_score(test_Y, testpred, average='weighted')\n",
        "test_accuracy_score = accuracy_score(test_Y, testpred, normalize=True)\n",
        "print(\"test_f1_score \"+str(test_f1_score) )\n",
        "print(\"test_precision_score \"+str(test_precision_score))\n",
        "print(\"test_recall_score \"+str(test_recall_score))\n",
        "print(\"test_accuracy_score \"+str(test_accuracy_score))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_f1_score 0.22155749790124293\n",
            "test_precision_score 0.21737261595457202\n",
            "test_recall_score 0.2294981640146879\n",
            "test_accuracy_score 0.2294981640146879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}